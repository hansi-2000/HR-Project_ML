{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## IMPORT LIBRARIES ##\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Import the required function for preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# To save the model import pickle\n",
        "import pickle\n",
        "\n",
        "train_url = 'https://drive.google.com/uc?export=download&id=1SlGTgYjSLKJsG41vFVvihZiGlRjBZff7'\n",
        "df = pd.read_csv(train_url)\n",
        "\n",
        "\n",
        "ordinal_mappings = {\n",
        "    'Decision_skill_possess': {'Directive': 1, 'Behavioral': 2, 'Analytical': 3, 'Conceptual': 4},\n",
        "    'Compensation_and_Benefits': {'type0': 1, 'type1': 2, 'type2': 3, 'type3': 4, 'type4':5}\n",
        "}\n",
        "\n",
        "for col, mapping in ordinal_mappings.items():\n",
        "    df[col] = df[col].map(mapping)\n",
        "\n",
        "df['Post_Level'].fillna(df['Post_Level'].median(), inplace=True)\n",
        "df['Pay_Scale'].fillna(df['Pay_Scale'].median(), inplace=True)\n",
        "df['Compensation_and_Benefits'].fillna(df['Compensation_and_Benefits'].mean(), inplace=True)\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "df = df.dropna(subset=['Time_of_service'])\n",
        "df = df.dropna(subset=['Age'])\n",
        "\n",
        "df_to_modelling = df[['Compensation_and_Benefits','Decision_skill_possess','Education_Level', 'Time_of_service', 'Time_since_promotion', 'Commute_Time_rate', 'Workload_Index', 'Pay_Scale', 'Post_Level', 'Growth_Rate', 'Yearly_Trainings', 'Weekly_Over_Time','Work_Life_Balance', 'Attrition_rate', 'Age']]\n",
        "df_new =df_to_modelling\n",
        "\n",
        "y = df_to_modelling['Attrition_rate']\n",
        "df_to_modelling = df_to_modelling.drop(['Attrition_rate'], axis=1)\n",
        "df_to_modelling['Pay_Scale'] = df_to_modelling['Pay_Scale'].astype(float)\n",
        "df_to_modelling['Age'] = df_to_modelling['Age'].astype(int)\n",
        "df_to_modelling['Post_Level'] = df_to_modelling['Post_Level'].astype(float)\n",
        "\n",
        "# Define function to handle outliers\n",
        "def clip_outliers(df, cols, threshold=1.5):\n",
        "    for col in cols:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - threshold * IQR\n",
        "        upper_bound = Q3 + threshold * IQR\n",
        "        df[col] = np.clip(df[col], lower_bound, upper_bound)\n",
        "    return df\n",
        "\n",
        "# Apply to selected numerical features\n",
        "num_features = [\"Age\", \"Time_of_service\", \"Commute_Time_rate\", \"Pay_Scale\", \"Yearly_Trainings\"]  # Adjust based on data\n",
        "df = clip_outliers(df, num_features)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df[num_features] = scaler.fit_transform(df[num_features])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_to_modelling_scaled = scaler.fit_transform(df_to_modelling)\n",
        "\n",
        "# Cap values beyond 99th percentile\n",
        "df['Commute_Time_rate'] = np.clip(df['Commute_Time_rate'], 0.05, 0.95)\n",
        "df['VAR7'] = np.clip(df['Work_Life_Balance'], df['Work_Life_Balance'].quantile(0.05), df['Work_Life_Balance'].quantile(0.95))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_to_modelling, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Hyperparameters\n",
        "gbm = lgb.LGBMRegressor(\n",
        "    random_state=42,\n",
        "    learning_rate=0.45,  # Reduce if needed\n",
        "    max_depth=15,  # Reduce depth\n",
        "    n_estimators=900,\n",
        "    min_child_samples=25,  # Increase from 30\n",
        "    colsample_bytree=0.8,\n",
        "    subsample=0.8,\n",
        "    lambda_l2=4 # Add back some L2 regularization\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model = gbm.fit(df_to_modelling, y)\n",
        "\n",
        "# Make predictions\n",
        "pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH8cWqbseVwU",
        "outputId": "eeb4153c-4d52-4225-aa6c-69a87ee3d218"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 218\n",
            "[LightGBM] [Info] Number of data points in the train set: 9940, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.245665\n",
            "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}